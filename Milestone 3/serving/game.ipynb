{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift6758.helper_ms3.helper import download_game_data, parse_game_events, augment_data, update_tracker, get_unprocessed_events, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'download_game_data' from 'ift6758' (/home/aries/6758/iftt6758_project/ift6758/ift6758/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mift6758\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_game_data, parse_game_events, augment_data, update_tracker, get_unprocessed_events, load_model\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize Flask app\u001b[39;00m\n\u001b[1;32m     11\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'download_game_data' from 'ift6758' (/home/aries/6758/iftt6758_project/ift6758/ift6758/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from flask import Flask, jsonify, request\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Logger setup\n",
    "LOG_FILE = \"game_client.log\"\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE, level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Directories and global variables\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "current_model = None\n",
    "current_model_name = None\n",
    "processed_events_tracker = {}\n",
    "\n",
    "\n",
    "#@app.before_first_request\n",
    "@app.before_request\n",
    "def before_first_request():\n",
    "    \"\"\"\n",
    "    Hook to handle any initialization before the first request (e.g. load model,\n",
    "    setup logging handler, etc.)\n",
    "    \"\"\"\n",
    "    app.before_request_funcs[None].remove(before_first_request)\n",
    "\n",
    "    # TODO: setup basic logging configuration\n",
    "    logger.info(\"Flask app initialized.\")\n",
    "\n",
    "    # TODO: any other initialization before the first request (e.g. load default model)\n",
    "    global current_model, current_model_name\n",
    "    \n",
    "    # Load default model (\"Distance Only\")\n",
    "    default_model_name = \"Distance_Angle\"\n",
    "    default_model_version = \"v0\"\n",
    "    default_model_path = os.path.join(model_dir, f\"{default_model_name}_model.pkl\")\n",
    "\n",
    "    # Check if the default model is already downloaded\n",
    "    if not os.path.exists(default_model_path):\n",
    "        logger.info(f\"Default model {default_model_name} not found locally. Downloading from WandB.\")\n",
    "        try:\n",
    "            logger.info(f\"Downloading model {default_model_name} version {default_model_version} from WandB registry.\")\n",
    "            wandb.init(project=\"ms2-logistic-regression\", mode=\"online\")\n",
    "            model_artifact = wandb.use_artifact(f\"{default_model_name}:{default_model_version}\", type=\"model\")\n",
    "            model_artifact.download(root=model_dir)\n",
    "            wandb.finish()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to download default model {default_model_name}: {e}\")\n",
    "            return \n",
    "\n",
    "    # Load the default model\n",
    "    current_model = load_model(default_model_path, logger)\n",
    "    if current_model:\n",
    "        current_model_name = f\"{default_model_name}_{default_model_version}\"\n",
    "        logger.info(f\"Default model {default_model_name} version {default_model_version} loaded successfully.\")\n",
    "    else:\n",
    "        logger.error(f\"Failed to load default model {default_model_name} version {default_model_version}.\")\n",
    "\n",
    "\n",
    "# Endpoint: /process_game\n",
    "@app.route(\"/process_game\", methods=[\"POST\"])\n",
    "def process_game():\n",
    "    \"\"\"\n",
    "    Processes game data for a given game_id, augments it, and predicts probabilities for unprocessed events.\n",
    "    \"\"\"\n",
    "    global current_model\n",
    "    if current_model is None:\n",
    "        logger.error(\"No model loaded.\")\n",
    "        return jsonify({\"error\": \"No model loaded.\"}), 400\n",
    "\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        game_id = data.get(\"game_id\")\n",
    "        if not game_id:\n",
    "            return jsonify({\"error\": \"Game ID is required.\"}), 400\n",
    "\n",
    "        # Download and parse game data\n",
    "        game_data = download_game_data(game_id)\n",
    "        if not game_data:\n",
    "            return jsonify({\"error\": \"Failed to download game data.\"}), 400\n",
    "\n",
    "        events_df = parse_game_events(game_data)\n",
    "        unprocessed_events = get_unprocessed_events(game_id, events_df, processed_events_tracker)\n",
    "\n",
    "        if unprocessed_events.empty:\n",
    "            return jsonify({\"message\": \"No new events to process.\"})\n",
    "\n",
    "        # Augment data for unprocessed events\n",
    "        augmented_events = augment_data(unprocessed_events)\n",
    "\n",
    "        # Predict probabilities for augmented events\n",
    "        augmented_events[\"predicted_probabilities\"] = current_model.predict_proba(\n",
    "            augmented_events[[\"distance_from_net\", \"angle_from_net\"]]\n",
    "        )[:, 1]\n",
    "\n",
    "        # Update tracker\n",
    "        update_tracker(game_id, unprocessed_events[\"event_id\"].tolist(), processed_events_tracker)\n",
    "\n",
    "        # Log processed events\n",
    "        logger.info(f\"Processed {len(unprocessed_events)} events for game ID {game_id}.\")\n",
    "        return augmented_events.to_json(orient=\"records\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to process game: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# Endpoint: /logs\n",
    "@app.route(\"/logs\", methods=[\"GET\"])\n",
    "def logs():\n",
    "    \"\"\"\n",
    "    Returns the logs as a response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(LOG_FILE, \"r\") as log_file:\n",
    "            log_data = log_file.read()\n",
    "        return f\"<pre>{log_data}</pre>\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch logs: {e}\")\n",
    "        return jsonify({\"error\": \"Could not retrieve logs.\"}), 500\n",
    "\n",
    "# Endpoint: /download_registry_model\n",
    "@app.route(\"/download_registry_model\", methods=[\"POST\"])\n",
    "def download_registry_model():\n",
    "    \"\"\"\n",
    "    Handles model downloading and swapping.\n",
    "    \"\"\"\n",
    "    global current_model, current_model_name\n",
    "    try:\n",
    "        # Parse request data\n",
    "        data = request.get_json()\n",
    "        workspace = data.get(\"workspace\")\n",
    "        model_name = data.get(\"model\")\n",
    "        version = data.get(\"version\")\n",
    "\n",
    "        if not all([workspace, model_name, version]):\n",
    "            return jsonify({\"error\": \"Missing required arguments: workspace, model, or version.\"}), 400\n",
    "\n",
    "        model_path = os.path.join(model_dir, f\"{model_name}_model.pkl\")\n",
    "\n",
    "        # Check if model exists locally\n",
    "        if os.path.exists(model_path):\n",
    "            logger.info(f\"Model {model_name} version {version} already exists locally. Loading it.\")\n",
    "        else:\n",
    "            # Download model from WandB\n",
    "            logger.info(f\"Downloading model {model_name} version {version} from WandB registry.\")\n",
    "            wandb.init(project=workspace, entity=\"IFT6758_2024-B01\", mode=\"online\")\n",
    "            model_artifact = wandb.use_artifact(f\"{model_name}:{version}\", type=\"model\")\n",
    "            model_artifact.download(root=model_dir)\n",
    "            wandb.finish()\n",
    "\n",
    "        # Load the downloaded model\n",
    "        current_model = load_model(model_path, logger)\n",
    "        if current_model:\n",
    "            current_model_name = f\"{model_name}_{version}\"\n",
    "            logger.info(f\"Successfully loaded model: {model_name} version {version}\")\n",
    "            return jsonify({\"message\": f\"Model {model_name} version {version} loaded successfully.\"})\n",
    "        else:\n",
    "            raise Exception(\"Failed to load model after downloading.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to download or load model: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# Endpoint: /predict\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    Handles POST requests for predictions.\n",
    "    \"\"\"\n",
    "    global current_model\n",
    "    if current_model is None:\n",
    "        logger.error(\"No model loaded.\")\n",
    "        return jsonify({\"error\": \"No model loaded.\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Parse input features\n",
    "        data = request.get_json()\n",
    "        if not data:\n",
    "            return jsonify({\"error\": \"No input data provided.\"}), 400\n",
    "\n",
    "        features_df = pd.DataFrame.from_dict(data)\n",
    "        predictions = current_model.predict_proba(features_df)[:, 1]\n",
    "        logger.info(\"Predictions made successfully.\")\n",
    "        return jsonify(predictions.tolist())\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Prediction failed: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n",
      "Successfully downloaded data for game ID: 2021020001\n",
      "Successfully downloaded data for game ID: 2021020001\n"
     ]
    }
   ],
   "source": [
    "app.run(host=\"0.0.0.0\", port=5001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift6758-conda-env",
   "language": "python",
   "name": "ift6758-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
